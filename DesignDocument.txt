			+--------------------+
			|    CompSci 143A    |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Basit Sheikh bsheikh@uci.edu
David Sianov <Dsianov@uci.edu>
Christopher Welde cwelde@uci.edu

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission or notes for the
>> TAs, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread 
	int64_t awake_thread;                /* Thread wakeup time in ticks. */ //ADDED
	struct semaphore my_semaphore_t; //ADDED
	struct list_elem list_for_all_timers;        /* List element for timer_wait_list. */ //ADDED

I added a linked list structure to hold all of the timers to each thread : struct list_elem list_for_all_timers;

I added a semaphore to the thread struct to make sure no race conditions can occur just in case: struct semaphore my_semaphore_t

I added an integer to the thread struct to keep track of what time the thread should wake up, which is the current time + ticks: int64_t awake_thread; 

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Timer sleep first checks if the ticks passed in is a positive non-zero number. If it is not, it returns.

Then, it calculates the elapsed time by calling timer_ticks()

It creates a pointer to a thread which points to the current active thread (retrieved using thread_current()).

Then it checks if the elapsed time is > 0, if it is not, it returns.

It sets the thread's wake up time to whatever the elapsed time is plus the ticks.

Then it puts the thread into a list in order, using list_insert_ordered and unlocks the lock.

In the interrupt handler, we increase the ticks and then while the list is not empty, we loop..

In each iteration, we create a pointer to a thread which points to the front of the list of threads.

We check if the ticks is less than the time it needs to be woken up, and if it is we exit the function.

If it is not, we lock the semaphore and pop the first node of threads from the list of threads.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

we use list_insert_ordered. In list_insert_ordered,

the order in the list is sorted by awake_thread(=>Thread wakeup time in ticks)

In this way, we can check the list from the beginning, and stop whenever the 

sleep_ticks is larger than the current ticks, which guarantees the later 

threads in the sleep list donâ€™t need to be checked. Overall, useing sort list 

minimizes the time spent.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

We insert something into the list in order, then lock the thread right before popping something from the list in the interrupt handler. So we lock inside of the timer_interrupt, and then we do not unlock the thread until we return to the end of timer_sleep. This means only one thread can enter the critical section at a time and be compared/removed from the list.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

We have a semapahore which we lock inside of the interrupt handler, and is not unlocked until we return to timer_sleep. This means only one interrupt can be handled at a time.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design because it felt like it covered all of the edge cases. We handle the case were multiple threads try to access the data and modify it, and we also handled the case where multiple interrupts occur. Without discarding them, we used the semaphore to restrict access to only one at a time for the important part which involves comparing/removing things from the list. Moreover, timer is interrpt and if we trun off interrupt, there is no race condtion. Race condition only can modify when interrupt is on. This why we use semapahore so that only one thread uses the share data.     

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Our idea was to add an integer for the initial priority for each thread as well as their current priority. We also have a boolean to check if the thread has been donated or not.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Our idea was to check if the lower priority is holding the lock, and if it is, we can then then "donate" the cpu time from the higher priority to the lower one by modifying the priority temporarily, and then switching it back after. However, every time we attempted to implement this solution it would affect the rest of our test cases and make them fail so we decided to remove them and comment it out. As of now, our solution has priority scheduling but does not include priority donation. We used the provided list struct to implement this.

We also completed thread_set_priority where we adjust the priority to the new value, and yield if necessary. We also completed thread_get_priority which just retrieves the current priority of the thread.


Thread 1 has the lock, but thread 3 wants it. However, it is blocked because it has a lower priority.
-----------------------------------------------------------------------------------------
.  Thread 1                  .  Thread 2                  .  Thread 3                   .
.  Priority 1                .  Priority 10               .  Priority 100               .
.  Has Lock                  .  No lock                   .  No lock [Request Blocked]  .
-----------------------------------------------------------------------------------------
Now, we implement the donation. Notice the priority of thread 3 is donated to thread 1
-----------------------------------------------------------------------------------------
.  Thread 1                  .  Thread 2                  .  Thread 3                   .
.  Priority 100              .  Priority 10               .  Priority 100               .
.  Has Lock                  .  No lock                   .  No lock [Request Blocked]  .
-----------------------------------------------------------------------------------------
Now we can unblock thread 3 ...
-----------------------------------------------------------------------------------------
.  Thread 1                  .  Thread 2                  .  Thread 3                   .
.  Priority 100              .  Priority 10               .  Priority 100               .
.  Has Lock                  .  No lock                   .  No Lock                    .
.  Orig priority: 1 									.
-----------------------------------------------------------------------------------------
And thread 3 acquires the lock...
-----------------------------------------------------------------------------------------
.  Thread 1                  .  Thread 2                  .  Thread 3                   .
.  Priority 100              .  Priority 10               .  Priority 100               .
.  No Lock                   .  No lock                   .  Has Lock, Executes         .
.  Orig priority: 1 									.
-----------------------------------------------------------------------------------------
Now we revert back to original priority for thread 1 and release the lock from thread 3:
-----------------------------------------------------------------------------------------
.  Thread 1                  .  Thread 2                  .  Thread 3                   .
.  Priority 1                .  Priority 10               .  Priority 100               .
.  No lock                   .  No lock                   .  No lock		        .
.  Orig priority: 1 									.
-----------------------------------------------------------------------------------------
Finally, give lock back to thread 1 and continue...
-----------------------------------------------------------------------------------------
.  Thread 1                  .  Thread 2                  .  Thread 3                   .
.  Priority 1                .  Priority 10               .  Priority 100               .
.  Has lock                  .  No lock                   .  No lock		        .
.  Orig priority: 1 									.
-----------------------------------------------------------------------------------------

Continue executing.... Thread 3 has executed through priority donation.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

We created 2 functions:

bool lower_priority(struct list_elem *arg1, struct list_elem *arg2);
bool higher_priority(struct list_elem *arg1, struct list_elem *arg2

The first function lower_priority compares two list's and if the first has a lower priority than the second, return true.

The second function higher_priority does the opposite and returns true when arg1 has a higher priority than arg2.

Inside the thread unblock function, we call llist_insert_ordered and pass higher_priority as the function pointer.

We then create a pointer to the current thread, and if that is not idle,and if that has a less priority than the thread passed into the function, we yield the thread with thread_yield() and return.

Otherwise, we return.

In thread_set_priority, we yield if necessary after comparing the priority of the element in the front of the list with the new priority that is passed in.




>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
	decrease the sema value by 0

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
	increase the sema value by 1
	if original priority > current priority
	set higher priority for that thread in lock list

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A potential race would be if multiple threads call thread_set_priority. In this case, theree will be a data race and they may change the value of the priority being assigned and assign the wrong one to each thread. To avoid this, you can use a simple mutex lock or sempahore so that the critical section where it is assigned is atomically executed.

Our idea of doing this was to have the caller function lock and unlock, and not the actual thread_set_priority function. There is minimal difference in this. Our approach is a bit less user friendly as it requires the developer to lock and unlock before and after calling the thread_set_priority function, but that's how we ended up deciding to do it. If we ever need to change it, it's a very simple change.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design because we felt like it was the best way to turn a conceptual idea into a physical model and apply it. We figured that by getting something working first, we should try to do it the simplest way possible to make sure we understand the idea of priority donation correctly. Then, after we do that we can slowly improve it.

In the end, we couldn't get the donation part working unfortunately.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.h
#define NICE_DEFAULT 0

struct thread
   int nice; 

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer |     recent_cpu      |        priority         |  thread
ticks   A   	B   	C   	A   	B   	C   	 to run
-----  --  	--  	--  	--  	--  	--   	------
 0	0	1	2	63	61	59	A
 4	4	1	2	62	61	59	A
 8	7	2	4	61	61	58	B
12	6	6	6	61	59	58	A
16	9	6	7	60	59	57	A
20	12	6	8	60	59	57	A
24	15	6	9	59	59	57	B
28	14	10	10	59	58	57	A
32	16	10	11	58	58	56	B
36	15	14	12	59	57	56	A

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

Yes. The ambiguity is the length of a timer tick interval. here, it is in multiples of four. However, that
wasn't specified elsewhere. We did not get to implement this part.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

It's possible that the CPU spends more time context switching than actually executing the thread.
It's important to not waste too much time switching stuff around and to allow threads to get enough
running time. Because if not, a consequence will be that our CPU cores may suffer and experience low performance.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

If we had more time to figure out how to get this working, I would approach it differently and instead try to utilize the ready_list that is already provided. A couple of things I would focus on would be

(A) Prevent starvation by some other technique, such as round robin integrated into the priority donation where if you give priority to a low process, it does not get to completely execute because it may take up a lot of time even though it isn't that important.

(B) Add helper functions to help print and debug outputs to understand everything better.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We did not reach this part of the project, so we cannot comment on it.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?
Chris - While I found the assignment fair and thought the given amount of time was fair, I think that it's
easy to underestimate the amount of work required for it because it's only 10% of the grade, so naturally you might
think it's not a lot of work, when it really is. In the future, I would cut the last homework or something and have the focus 
be on the project.
Basit - The idea behind the assignment is good, and it relates to the class. However, there was very little guidance and as such it was difficult to figure out to connect all the moving parts. We understood how to implement prioritization and such theoretically, but applying it to this existing base was difficult and tedious. 
David - it think is realy hard project since there is no easy way to debug. 

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?
Yes

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?
Basit - It was hard to find answers to questions that we had, particularly because of the large scale of the project. If the project was scaled down to an individualized programming project it would be much easier to get feedback and guidance from the TAs.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?
Basit - I think that instead of giving an entire existing code base to work with, it should be a project where the users can create their own threads and their own queue and mantain stuff like that. It was difficult to work with the existing code.

>> Any other comments?
